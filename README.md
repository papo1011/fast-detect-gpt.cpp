```bash
███████  █████  ███████ ████████    ██████  ███████ ████████ ███████  ██████ ████████     ██████  ██████ ████████
██      ██   ██ ██         ██       ██   ██ ██         ██    ██      ██         ██       ██       ██  ██    ██
█████   ███████ ███████    ██       ██   ██ █████      ██    █████   ██         ██       ██   ███ ██████    ██
██      ██   ██      ██    ██       ██   ██ ██         ██    ██      ██         ██       ██    ██ ██        ██
██      ██   ██ ███████    ██       ██████  ███████    ██    ███████  ██████    ██        ██████  ██        ██
```

# What is fast-detect-gpt.cpp?

It is a 200 lines wrapper around llama.cpp to enable detection of AI generated text.
If you want to dig into the details of how it works, read the fast detect gpt paper
[![arXiv](https://img.shields.io/badge/arXiv-2310.05130-b31b1b.svg)](https://arxiv.org/abs/2310.05130)

This implementation follows the analytic Fast DetectGPT approach, which optimizes detection speed by utilizing a
singular model for both sampling and scoring. Unlike previous methods (DetectGPT) that required separate steps or
models,
this approach combines the processes, necessitating only one model call per check.
The core metric is the Conditional Probability Curvature, defined as:
$$d(x, p_\theta) = \frac{\log p_\theta(x) - \tilde{\mu}}{\tilde{\sigma}}$$
Where:

- $x$ -> The original input token
- $\log p_\theta(x)$ -> The *log likelihood* of the original token
- $\tilde{\mu}$ -> The average log likelihood of alternative samples generated by the model
- $\tilde{\sigma}$ -> The standard deviation of those sample *log likelihoods*

<p align="center">
  <img src="https://francescopapini.com/assets/img/projects/detectgpt.png" alt="DetectGPT" width="400"/>
</p>

The algorithm assumes that AI generated text resides in the peaks of the model's probability curvature, as clearly
illustrated in the previous figure from the [DetectGPT paper](https://arxiv.org/abs/2301.11305). Instead of relying on
computationally expensive sampling to
generate local neighbors, the analytical implementation directly evaluates the model's predictive distribution
for each token. By computing the theoretical expectation and variance of the conditional *log probabilities*, we obtain
an exact estimate of the local curvature.The metric normalizes the difference between the observed *log likelihood* and
its analytical expectation ($\tilde{\mu}$, representing the negative entropy) by dividing it by the analytical standard
deviation $\tilde{\sigma}$. This renders the metric a robust and deterministic zero shot detector, capable of
distinguishing between human and AI written text with high accuracy and minimal latency.

### How to compile

```bash
   cmake .
   cmake --build ./build --target fast-detect-gpt -j 6
```